{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "473f92e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from random import shuffle\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "from numpy import sum\n",
    "from mrcfile import open as mrc_open\n",
    "from PIL import Image\n",
    "from skimage.exposure import equalize_adapthist as clahe\n",
    "from skimage.transform import rescale\n",
    "import torch\n",
    "\n",
    "def norm_minmax(x):\n",
    "    x -= x.min()\n",
    "    return x / x.max()\n",
    "\n",
    "def mrc_to_img(path_to_mrc, scale=0.1):\n",
    "    with mrc_open(path_to_mrc) as mrc:\n",
    "        x = mrc.data\n",
    "    x = sum(x, axis=0)\n",
    "    x = norm_minmax(x)\n",
    "    x = clahe(x)\n",
    "    return rescale(x, scale)\n",
    "\n",
    "class XMLMetadata:\n",
    "    def __init__(self, source_dir):\n",
    "        self.source_dir = source_dir\n",
    "        self._data = dict()\n",
    "        for path_to_xml in glob.glob(os.path.join(source_dir, \"*.xml\")):\n",
    "            # shared by a .mrc\n",
    "            name = path_to_xml[path_to_xml.rfind('/')+1:-4]\n",
    "            self._data[name] = dict()\n",
    "            # python's xml parser sucks\n",
    "            metadata = ET.parse(path_to_xml)\n",
    "            root = metadata.getroot()\n",
    "            w, h = [int(x.text) for x in root[0][8][2:4]]\n",
    "            nb_fractions = int(root[0][6].text)\n",
    "            self._data[name][\"shape\"] = [nb_fractions,w,h]\n",
    "            # todo: ... do i need any of this metadata?\n",
    "            \n",
    "    def list_files(self):\n",
    "        return list(self._data.keys())\n",
    "            \n",
    "    def __getitem__(self, key):\n",
    "        return self._data[key]\n",
    "    \n",
    "class MRCSampler:\n",
    "    \n",
    "    def __init__(self, path_to_mrc, tile_size, tile_stride, scale=1):\n",
    "        assert scale <= 1, \"really don't need to do that\"\n",
    "        self.source_file = path_to_mrc\n",
    "        self.tile_size = tile_size\n",
    "        self.tile_stride = tile_stride\n",
    "        self.img = mrc_to_img(path_to_mrc, scale)\n",
    "        w,h = self.img.shape\n",
    "        self.cols = w // tile_stride + 1\n",
    "        self.rows = h // tile_stride + 1\n",
    "        self.I = list(range(len(self)))\n",
    "        shuffle(self.I)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        row = idx // self.rows\n",
    "        col = idx % self.rows\n",
    "        l = row * self.tile_stride\n",
    "        r = l + self.tile_size\n",
    "        t = col * self.tile_stride\n",
    "        b = t + self.tile_size\n",
    "        return self.img[l:r,t:b]\n",
    "    \n",
    "    def get_tile(self, i):\n",
    "        return self.__getitem__(self.I[i])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.cols * self.rows\n",
    "    \n",
    "    @classmethod\n",
    "    def get_factory(cls, tile_dim, stride, scale):\n",
    "        return lambda path_to_mrc: cls(path_to_mrc, tile_dim, stride, scale=scale)\n",
    "\n",
    "class MRCData(torch.utils.data.IterableDataset):\n",
    "    def __init__(self, source_dir, sampler_factory, transform=None, K=1):\n",
    "        super(MRCData, self).__init__()\n",
    "        self.transform = transform\n",
    "        self.K = K\n",
    "        # method for generating MRCSampler objects\n",
    "        self._sampler_factory = sampler_factory\n",
    "        # glob all the mrc files in the source directory\n",
    "        self.source_dir = source_dir\n",
    "        self.mrc_files = glob.glob(os.path.join(source_dir, \"*.mrc\"))\n",
    "        # load metadata\n",
    "        self.metadata = XMLMetadata(source_dir)\n",
    "        \n",
    "    def _refresh_sampler(self):\n",
    "        print(\"loc\",self._loc)\n",
    "        self._sampler = self._sampler_factory(self.mrc_files[self._loc])\n",
    "        self._loc = (self._loc + 1) % len(self.mrc_files)\n",
    "        self._idx = 0\n",
    "        \n",
    "    def __next__(self):\n",
    "        # go to the next sampler if this one is depleted\n",
    "        if self._idx >= len(self._sampler):\n",
    "            if self.depleted:\n",
    "                raise StopIteration\n",
    "            print(f\"sampler refresh:\\nsampler\\t{self._sampler.source_file} {len(self._sampler)}\\nidx\\t{self._idx}\\nloc\\t{self._loc}\")\n",
    "            self._refresh_sampler()\n",
    "            if self._loc == 0:\n",
    "                self.depleted = True\n",
    "        # get a randomly-sampled tile from the image\n",
    "        img = self._sampler.get_tile(self._idx)\n",
    "        self._idx += 1\n",
    "        # conditionally generate K augmentations of the image\n",
    "        # see https://github.com/mpatacchiola/self-supervised-relational-reasoning/\n",
    "        pic = Image.fromarray(img)\n",
    "        img_list = list()\n",
    "        if self.transform is not None:\n",
    "            for _ in range(self.K):\n",
    "                img_transformed = self.transform(pic.copy())\n",
    "                img_list.append(img_transformed)\n",
    "        else:\n",
    "            img_list = img\n",
    "        print(self._idx, self._sampler.source_file)\n",
    "        return img_list\n",
    "        \n",
    "    def __iter__(self):\n",
    "        shuffle(self.mrc_files)\n",
    "        self.depleted = False\n",
    "        self._idx = 0\n",
    "        self._loc = 0\n",
    "        self._refresh_sampler()\n",
    "        if torch.utils.data.get_worker_info() is not None:\n",
    "            raise NotImplemented(\"this class doesn't support multiprocess loading (yet)\")\n",
    "        return self\n",
    "            \n",
    "    # todo: calculates length from the nb of files, their dimensions, and the sampling parameters\n",
    "    # def __len__():\n",
    "    #     assert self.uniform, \"cannot calculate __len__ on a non-uniform dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "12da10a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sampler = MRCSampler(\"../data/brians_data/0417.mrc\", 50, 20, scale = 0.1)\n",
    "factory = MRCSampler.get_factory(50,20,0.1)\n",
    "ds = MRCData(\"../data/brians_data\", factory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
